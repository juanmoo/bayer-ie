{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.abspath('./src'))\n",
    "import utils, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATHS\n",
    "data_path = '/scratch/juanmoo1'\n",
    "EMA_dump_path = os.path.join(data_path, './jsons/EMA_dump.json')\n",
    "EMA_xmls_path = os.path.join(data_path, './xmls/')\n",
    "EMA_annotations_path = os.path.join(data_path, './bayer/VendorEMAforMIT/annotations.xlsx')\n",
    "\n",
    "pickle_dumps_path = os.path.join(data_path, './pickle_dumps/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, os\n",
    "\n",
    "def save_value(key, val):\n",
    "    with open(os.path.join(pickle_dumps_path, 'checkpoint.pickle'), 'rb') as f:\n",
    "        try:\n",
    "            saved_env = pickle.load(f)\n",
    "            saved_env.keys()\n",
    "        except:\n",
    "            saved_env = dict()\n",
    "            \n",
    "    saved_env[key] = val\n",
    "    \n",
    "    with open(os.path.join(pickle_dumps_path, 'checkpoint.pickle'), 'wb') as f:\n",
    "        f.write(pickle.dumps(saved_env))\n",
    "    \n",
    "def load_value(key):\n",
    "    with open(os.path.join(pickle_dumps_path, 'checkpoint.pickle'), 'rb') as f:\n",
    "        s = f.read()\n",
    "        try:\n",
    "            saved_env = pickle.loads(s)\n",
    "            ans = saved_env[key]\n",
    "        except:\n",
    "            ans = None\n",
    "        \n",
    "        return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_documents = load_value('processed_documents')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def cross_validation(doc_list, train_algo, test_algo, k, verbose=False, config=None):\n",
    "    N = len(doc_list)\n",
    "    size = N//k\n",
    "    indeces = list(range(N))\n",
    "    random.shuffle(indeces)\n",
    "    all_indeces = set(indeces)\n",
    "    \n",
    "    pres_list = []\n",
    "    rec_list = []\n",
    "    \n",
    "    for j in range(N//size):\n",
    "        train_indeces = indeces[j * size:(j + 1) * size] + indeces[size * k + j: size * k + j + 1]\n",
    "        test_indeces = list(all_indeces - set(train_indeces))\n",
    "        \n",
    "        train_docs = [doc_list[i] for i in train_indeces]\n",
    "        test_docs = [doc_list[i] for i in test_indeces]\n",
    "        \n",
    "        if verbose:\n",
    "            print('Fold %d starting!'%(j + 1))\n",
    "        \n",
    "        m, tt, ht = train_algo(train_docs, config=config)\n",
    "        pres, rec = test_algo(m, tt, ht, test_docs)\n",
    "        \n",
    "        pres_list.append(pres)\n",
    "        rec_list.append(rec)\n",
    "        \n",
    "        if verbose:\n",
    "            print('precision:', pres)\n",
    "            print('recall:', rec)\n",
    "            print('-' * 10 + '\\n')\n",
    "    \n",
    "    return sum(pres_list)/k, sum(rec_list)/k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack, vstack\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "def model_test(model, text_tokenizer, header_tokenizer, doc_list, use_headers = True):\n",
    "    test_texts = reduce(lambda x, y: x + y, [[]] + [processed_documents[doc_name]['texts'] for doc_name in doc_list])\n",
    "    tokenized_texts = text_tokenizer.transform(test_texts)\n",
    "    test_labels = reduce(lambda x, y: x + y, [[]] + [processed_documents[doc_name]['labels'] for doc_name in doc_list])\n",
    "    \n",
    "    if use_headers:\n",
    "        test_header1 = reduce(lambda x, y: x + y, [[]] + [processed_documents[doc_name]['header1'] for doc_name in doc_list])\n",
    "        test_header2 = reduce(lambda x, y: x + y, [[]] + [processed_documents[doc_name]['header2'] for doc_name in doc_list])\n",
    "        tokenized_header1 = header_tokenizer.transform(test_header1)\n",
    "        tokenized_header2 = header_tokenizer.transform(test_header2)\n",
    "        X_test = hstack([tokenized_texts, tokenized_header1, tokenized_header2])\n",
    "    else:\n",
    "        X_test = tokenized_texts\n",
    "        \n",
    "    Y_test = test_labels\n",
    "    pred = model.predict(X_test)\n",
    "    cm = np.array(confusion_matrix(Y_test, pred))\n",
    "    \n",
    "    # Diagonal elemetns were correctly classified\n",
    "    diagonal = cm.diagonal()\n",
    "    \n",
    "    # Input class Counts\n",
    "    class_sum = cm.sum(axis=1)\n",
    "    \n",
    "    # Predicted class counts\n",
    "    pred_sum = cm.sum(axis=0)\n",
    "    \n",
    "    # Per-class performance w/ no-examples -> 0 perf\n",
    "    precision = np.where(class_sum == 0, 0, diagonal/class_sum)\n",
    "    recall = np.where(pred_sum == 0, 0, diagonal/pred_sum)\n",
    "    \n",
    "    # Frequency Weighted Performance\n",
    "    c_freq = cm.sum(axis=1)/cm.sum()\n",
    "    pres = c_freq * precision\n",
    "    rec = c_freq * recall\n",
    "    \n",
    "    # Remove 'other' Category\n",
    "    c_freq = c_freq[0:1] + c_freq[2:]\n",
    "    pres = pres[0:1] + pres[2:]\n",
    "    rec = rec[0:1] + rec[2:]\n",
    "    \n",
    "    return pres.sum()/c_freq.sum(), rec.sum()/c_freq.sum(), cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "def mlp_train(doc_list, config=None, use_headers=True):\n",
    "    train_texts = reduce(lambda x, y: x + y, [[]] + [processed_documents[doc_name]['texts'] for doc_name in doc_list])\n",
    "    train_labels = reduce(lambda x, y: x + y, [[]] + [processed_documents[doc_name]['labels'] for doc_name in doc_list])\n",
    "    \n",
    "    if use_headers:\n",
    "        train_header1 = reduce(lambda x, y: x + y, [[]] + [processed_documents[doc_name]['header1'] for doc_name in doc_list])\n",
    "        train_header2 = reduce(lambda x, y: x + y, [[]] + [processed_documents[doc_name]['header2'] for doc_name in doc_list])\n",
    "\n",
    "    if config is None:\n",
    "        config = load_value('best_config_header')\n",
    "        \n",
    "    text_tokenizer = CountVectorizer(ngram_range=config['ngram_config'], stop_words=config['stop_config'])\n",
    "    \n",
    "    if use_headers:\n",
    "        header_tokenizer = CountVectorizer(ngram_range=config['ngram_config'], stop_words=config['stop_config'])\n",
    "        tokenized_header1 = header_tokenizer.fit_transform(train_header1)\n",
    "        tokenized_header2 = header_tokenizer.transform(train_header2)\n",
    "    else:\n",
    "        header_tokenizer = None\n",
    "\n",
    "    \n",
    "    tokenized_texts = text_tokenizer.fit_transform(train_texts)\n",
    "    \n",
    "    if use_headers:\n",
    "        X_train = hstack([tokenized_texts, tokenized_header1, tokenized_header2])\n",
    "    else:\n",
    "        X_train = tokenized_texts\n",
    "        \n",
    "        \n",
    "    Y_train = train_labels\n",
    "    \n",
    "    model = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(100, 100), random_state=None, verbose=True)\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    return (model, text_tokenizer, header_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.42394903\n",
      "Iteration 2, loss = 0.09654049\n",
      "Iteration 3, loss = 0.05834669\n",
      "Iteration 4, loss = 0.04552078\n",
      "Iteration 5, loss = 0.03875755\n",
      "Iteration 6, loss = 0.03603909\n",
      "Iteration 7, loss = 0.03344196\n",
      "Iteration 8, loss = 0.03180807\n",
      "Iteration 9, loss = 0.03088413\n",
      "Iteration 10, loss = 0.02959805\n",
      "Iteration 11, loss = 0.02924986\n",
      "Iteration 12, loss = 0.02878188\n",
      "Iteration 13, loss = 0.02848419\n",
      "Iteration 14, loss = 0.02819246\n",
      "Iteration 15, loss = 0.02748516\n",
      "Iteration 16, loss = 0.02750734\n",
      "Iteration 17, loss = 0.02704540\n",
      "Iteration 18, loss = 0.02705784\n",
      "Iteration 19, loss = 0.02642833\n",
      "Iteration 20, loss = 0.02735820\n",
      "Iteration 21, loss = 0.02654729\n",
      "Iteration 22, loss = 0.02644453\n",
      "Iteration 23, loss = 0.02622576\n",
      "Iteration 24, loss = 0.02587575\n",
      "Iteration 25, loss = 0.02596482\n",
      "Iteration 26, loss = 0.02593038\n",
      "Iteration 27, loss = 0.02577982\n",
      "Iteration 28, loss = 0.02543931\n",
      "Iteration 29, loss = 0.02560631\n",
      "Iteration 30, loss = 0.02541220\n",
      "Iteration 31, loss = 0.02513286\n",
      "Iteration 32, loss = 0.02555406\n",
      "Iteration 33, loss = 0.02542576\n",
      "Iteration 34, loss = 0.02525599\n",
      "Iteration 35, loss = 0.02508082\n",
      "Iteration 36, loss = 0.02586080\n",
      "Iteration 37, loss = 0.02794841\n",
      "Iteration 38, loss = 0.02895631\n",
      "Iteration 39, loss = 0.03272626\n",
      "Iteration 40, loss = 0.02811177\n",
      "Iteration 41, loss = 0.02475360\n",
      "Iteration 42, loss = 0.02567598\n",
      "Iteration 43, loss = 0.02466510\n",
      "Iteration 44, loss = 0.02461206\n",
      "Iteration 45, loss = 0.02486713\n",
      "Iteration 46, loss = 0.02474808\n",
      "Iteration 47, loss = 0.02441593\n",
      "Iteration 48, loss = 0.02425226\n",
      "Iteration 49, loss = 0.02425514\n",
      "Iteration 50, loss = 0.02422339\n",
      "Iteration 51, loss = 0.02443113\n",
      "Iteration 52, loss = 0.02423483\n",
      "Iteration 53, loss = 0.02424869\n",
      "Iteration 54, loss = 0.02423367\n",
      "Iteration 55, loss = 0.02442291\n",
      "Iteration 56, loss = 0.02415051\n",
      "Iteration 57, loss = 0.02426479\n",
      "Iteration 58, loss = 0.02410403\n",
      "Iteration 59, loss = 0.02406364\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "m, tt, ht = mlp_train(list(processed_documents), config=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, r, cm = model_test(m, tt, ht, list(processed_documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8451717734447539\n",
      "Recall: 0.8891629383142611\n",
      "[[  214     9     0     0     0     0     0     0     0     2     0    39]\n",
      " [   23 25159     1     0     1     2     0     0     0    22     4    17]\n",
      " [    0     4   119     0     0     0     0     0     0     0     0     0]\n",
      " [    0     7     0    85     0     0     0     0     0     0     0     0]\n",
      " [    0     2     0     0    38     0     0     0     0     0     0     1]\n",
      " [    0    24     1     0     0    51     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     1     0     0     0     0     0]\n",
      " [    1     6     0     0     0     0     0    30     0     0     0     4]\n",
      " [    0     0     0     0     0     0     0     0     4     0     0     0]\n",
      " [    1    39     0     0     0     0     0     0     0   289     0     9]\n",
      " [    0     0     0     0     0     0     0     0     0     0    21     0]\n",
      " [   10    57     0     0     0     0     0     1     0     0     0   863]]\n"
     ]
    }
   ],
   "source": [
    "print('Precision:', p)\n",
    "print('Recall:', r)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "save_value('neural_model_100_100', m)\n",
    "save_value('neural_model_tt_100_100', tt)\n",
    "save_value('neural_model_ht_100_100', ht)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 80/20 Train-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Split\n",
    "import random\n",
    "\n",
    "names = list(processed_documents)\n",
    "random.shuffle(names)\n",
    "\n",
    "i = int(.8 * len(names))\n",
    "train_docs = names[:i]\n",
    "test_docs = names[i:]\n",
    "\n",
    "# Save Used Split\n",
    "save_value('8020_split_train', train_docs)\n",
    "save_value('8020_split_test', test_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.52337805\n",
      "Iteration 2, loss = 0.10967314\n",
      "Iteration 3, loss = 0.06513091\n",
      "Iteration 4, loss = 0.05140556\n",
      "Iteration 5, loss = 0.04262207\n",
      "Iteration 6, loss = 0.03943536\n",
      "Iteration 7, loss = 0.03670238\n",
      "Iteration 8, loss = 0.03456121\n",
      "Iteration 9, loss = 0.03334999\n",
      "Iteration 10, loss = 0.03309002\n",
      "Iteration 11, loss = 0.03212916\n",
      "Iteration 12, loss = 0.03062918\n",
      "Iteration 13, loss = 0.03004202\n",
      "Iteration 14, loss = 0.03040245\n",
      "Iteration 15, loss = 0.03014385\n",
      "Iteration 16, loss = 0.02993898\n",
      "Iteration 17, loss = 0.02914089\n",
      "Iteration 18, loss = 0.02938927\n",
      "Iteration 19, loss = 0.02816157\n",
      "Iteration 20, loss = 0.02848160\n",
      "Iteration 21, loss = 0.02815876\n",
      "Iteration 22, loss = 0.02791965\n",
      "Iteration 23, loss = 0.02752088\n",
      "Iteration 24, loss = 0.02760487\n",
      "Iteration 25, loss = 0.02714258\n",
      "Iteration 26, loss = 0.02744343\n"
     ]
    }
   ],
   "source": [
    "# Model Training\n",
    "m2, tt2, ht2 = mlp_train(train_docs, config=None, use_headers=True)\n",
    "\n",
    "# Save Model\n",
    "save_value('neural_model_100_100_8020', m2)\n",
    "save_value('neural_model_tt_100_100_8020', tt2)\n",
    "save_value('neural_model_ht_100_100_8020', ht2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = load_value('neural_model_100_100_8020')\n",
    "tt2 = load_value('neural_model_tt_100_100_8020')\n",
    "ht2 = load_value('neural_model_ht_100_100_8020')\n",
    "# Model Test\n",
    "p, r, cm = model_test(m2, tt2, ht2, test_docs)\n",
    "print('Precision:', p)\n",
    "print('Recall:', r)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without Headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.56314502\n",
      "Iteration 2, loss = 0.12537349\n",
      "Iteration 3, loss = 0.08026345\n",
      "Iteration 4, loss = 0.06622139\n",
      "Iteration 5, loss = 0.05712021\n",
      "Iteration 6, loss = 0.05104173\n",
      "Iteration 7, loss = 0.04939483\n",
      "Iteration 8, loss = 0.04801441\n",
      "Iteration 9, loss = 0.04716561\n",
      "Iteration 10, loss = 0.04639908\n",
      "Iteration 11, loss = 0.04508791\n",
      "Iteration 12, loss = 0.04596397\n",
      "Iteration 13, loss = 0.04444380\n",
      "Iteration 14, loss = 0.04442796\n",
      "Iteration 15, loss = 0.04403545\n",
      "Iteration 16, loss = 0.04320014\n",
      "Iteration 17, loss = 0.04549352\n",
      "Iteration 18, loss = 0.04350482\n",
      "Iteration 19, loss = 0.04310921\n",
      "Iteration 20, loss = 0.04252026\n",
      "Iteration 21, loss = 0.04250790\n",
      "Iteration 22, loss = 0.04237036\n",
      "Iteration 23, loss = 0.04256695\n",
      "Iteration 24, loss = 0.04243339\n",
      "Iteration 25, loss = 0.04217606\n",
      "Iteration 26, loss = 0.04198119\n",
      "Iteration 27, loss = 0.04228552\n",
      "Iteration 28, loss = 0.04226891\n",
      "Iteration 29, loss = 0.04188171\n",
      "Iteration 30, loss = 0.04201180\n",
      "Iteration 31, loss = 0.04202332\n",
      "Iteration 32, loss = 0.04182182\n",
      "Iteration 33, loss = 0.04157782\n",
      "Iteration 34, loss = 0.04154029\n",
      "Iteration 35, loss = 0.04195205\n",
      "Iteration 36, loss = 0.04202425\n",
      "Iteration 37, loss = 0.04218409\n",
      "Iteration 38, loss = 0.04291242\n",
      "Iteration 39, loss = 0.04177759\n",
      "Iteration 40, loss = 0.04481306\n",
      "Iteration 41, loss = 0.04140382\n",
      "Iteration 42, loss = 0.04139899\n",
      "Iteration 43, loss = 0.04148624\n",
      "Iteration 44, loss = 0.04145842\n",
      "Iteration 45, loss = 0.04121173\n",
      "Iteration 46, loss = 0.04160271\n",
      "Iteration 47, loss = 0.04195059\n",
      "Iteration 48, loss = 0.04112429\n",
      "Iteration 49, loss = 0.04174642\n",
      "Iteration 50, loss = 0.04082632\n",
      "Iteration 51, loss = 0.04191040\n",
      "Iteration 52, loss = 0.04176972\n",
      "Iteration 53, loss = 0.04167277\n",
      "Iteration 54, loss = 0.04251603\n",
      "Iteration 55, loss = 0.04247053\n",
      "Iteration 56, loss = 0.04219020\n",
      "Iteration 57, loss = 0.04528337\n",
      "Iteration 58, loss = 0.04306732\n",
      "Iteration 59, loss = 0.04328006\n",
      "Iteration 60, loss = 0.04087522\n",
      "Iteration 61, loss = 0.04105834\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "m3, tt3, ht3 = mlp_train(train_docs, config=None, use_headers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "save_value('neural_model_100_100_nohead', m3)\n",
    "save_value('neural_model_tt_100_100_nohead', tt3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Test\n",
    "m3 = load_value('neural_model_100_100_nohead')\n",
    "tt3 = load_value('neural_model_tt_100_100_nohead')\n",
    "ht3 = None\n",
    "\n",
    "p, r, cm = model_test(m3, tt3, ht3, list(processed_documents), use_headers=False)\n",
    "print('Precision:', p)\n",
    "print('Recall:', r)\n",
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
