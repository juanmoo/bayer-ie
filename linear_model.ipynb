{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.abspath('./src'))\n",
    "import utils, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATHS\n",
    "data_path = '/scratch/juanmoo1'\n",
    "EMA_dump_path = os.path.join(data_path, './jsons/EMA_dump.json')\n",
    "EMA_xmls_path = os.path.join(data_path, './xmls/')\n",
    "EMA_annotations_path = os.path.join(data_path, './bayer/VendorEMAforMIT/annotations.xlsx')\n",
    "\n",
    "pickle_dumps_path = os.path.join(data_path, './pickle_dumps/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw Data\n",
    "'''\n",
    "Format:\n",
    "{\n",
    "    document_name <str>: {\n",
    "                            element_text: <str> (raw text),\n",
    "                            element_tag: <str> (TEI XML tag)\n",
    "                          },\n",
    "                          \n",
    "    ...\n",
    "}\n",
    "'''\n",
    "data = json.loads(open(EMA_dump_path, 'r').read())\n",
    "\n",
    "\n",
    "# Labels\n",
    "'''\n",
    "Dict in form:\n",
    "{\n",
    "    file_name: {\n",
    "        texts: [ <str>, ...],\n",
    "        labels: [ <str>, ...]\n",
    "    },\n",
    "    \n",
    "    ...\n",
    "    \n",
    "}\n",
    "'''\n",
    "annotations = utils.parse_spreadsheet(EMA_annotations_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching Data to Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "For each document in 'data', iterate through the paragraphs and check to see if there's \n",
    "an elemenet the paragraphs of the element in 'labels' with the same name.\n",
    "'''\n",
    "from matplotlib.pyplot import hist, title\n",
    "from fuzzywuzzy import fuzz\n",
    "from time import time as time\n",
    "\n",
    "def f1(piece, whole):\n",
    "    return piece in whole\n",
    "\n",
    "def f2(piece, whole):\n",
    "    return piece.lower() in whole.lower()\n",
    "\n",
    "def f3(piece, whole):\n",
    "    threshold = 95\n",
    "    return fuzz.partial_ratio(piece, whole) >= threshold\n",
    "\n",
    "def contains_test(piece, whole):\n",
    "    # test if 'piece' is a member of 'whole'\n",
    "    \n",
    "    test_functions = [f1, f2, f3]\n",
    "    \n",
    "    i = 0\n",
    "    return test_functions[i](piece, whole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_frac = []\n",
    "elapsed_times = []\n",
    "\n",
    "labeled_raw_documents = {}\n",
    "\n",
    "for parsed_doc_name in data:\n",
    "    start_time = time()\n",
    "\n",
    "    parsed_doc = data[parsed_doc_name]\n",
    "    label_doc = annotations[parsed_doc_name] #label doc w/ same name\n",
    "    \n",
    "    matchings = [] # el: [parsed paragraph, label_paragraph_id, label]\n",
    "    other = []\n",
    "    \n",
    "    paragraphs = []\n",
    "    labels = []\n",
    "    tags = []\n",
    "    \n",
    "    for parsed_p, tag in zip(parsed_doc['element_text'], parsed_doc['element_tag']):\n",
    "        found = False\n",
    "        for i, label_p in enumerate(label_doc['texts']):\n",
    "            if contains_test(parsed_p, label_p): #Match\n",
    "                found = True\n",
    "                matchings.append([parsed_p, i, label_doc['labels'][i]])\n",
    "                \n",
    "                paragraphs.append(parsed_p)\n",
    "                labels.append(label_doc['labels'][i])\n",
    "                tags.append(tag)\n",
    "                break\n",
    "        if not found:\n",
    "            other.append(parsed_p)\n",
    "            \n",
    "            paragraphs.append(parsed_p)\n",
    "            labels.append('other')\n",
    "            tags.append(tag)\n",
    "            \n",
    "    \n",
    "    tot_time = time() - start_time\n",
    "    elapsed_times.append(tot_time)\n",
    "            \n",
    "    num_texts = len(parsed_doc['element_text'])        \n",
    "    match_frac.append(len(matchings)/num_texts)\n",
    "    \n",
    "    labeled_raw_documents[parsed_doc_name] = {\n",
    "        'matches': matchings,\n",
    "        'other': other,\n",
    "        'paragraphs': paragraphs,\n",
    "        'labels': labels,\n",
    "        'tags': tags\n",
    "    }        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(os.path.join(pickle_dumps_path, 'EMA.pickle'), 'wb') as f:\n",
    "    f.write(pickle.dumps(labeled_raw_documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(os.path.join(pickle_dumps_path, 'EMA_fuzzy.pickle'), 'rb') as f:\n",
    "    labeled_raw_documents = pickle.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(elapsed_times)\n",
    "print(sum(elapsed_times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Matches: 0.0507364268205674\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([14., 17., 11.,  8.,  2.,  0.,  0.,  0.,  0.,  1.]),\n",
       " array([0.        , 0.02475172, 0.04950344, 0.07425516, 0.09900688,\n",
       "        0.12375859, 0.14851031, 0.17326203, 0.19801375, 0.22276547,\n",
       "        0.24751719]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Average Matches:\", sum(match_frac)/len(match_frac))\n",
    "hist(match_frac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjecture:\n",
    "The fraction of text in the labels is much smaller than all text. Thus, we should fail to find labels for most of extracted paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([11., 10.,  3.,  1.,  9.,  4.,  3.,  3.,  2.,  2.]),\n",
       " array([0.01782014, 0.03259288, 0.04736563, 0.06213837, 0.07691112,\n",
       "        0.09168386, 0.10645661, 0.12122935, 0.1360021 , 0.15077484,\n",
       "        0.16554759]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_ratios = []\n",
    "for parsed_doc_name in data:\n",
    "    parsed_doc = data[parsed_doc_name]\n",
    "    label_doc = annotations[parsed_doc_name]\n",
    "    \n",
    "    parsed_text = ''.join(e.strip() for e in parsed_doc['element_text'])\n",
    "    label_text = ''.join(e.strip() for e in label_doc['texts'])\n",
    "    \n",
    "    ratio = len(label_text)/len(parsed_text)\n",
    "    data_ratios.append(ratio)\n",
    "data_ratios.sort()\n",
    "\n",
    "# Cut lowest 5% and top 5%\n",
    "start = int(0.05 * len(data_ratios))\n",
    "end = int(0.95 * len(data_ratios))\n",
    "\n",
    "title(\"Total Text to Labeled Text Ratio\")\n",
    "hist(data_ratios[start:end])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "There seem to be missing documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anotation names count: 72\n",
      "document count: 53\n",
      "missing annotations count: 0\n",
      "missing doc count: 19\n",
      "missing docs:\n",
      "- blincyto-epar-product-information_en\n",
      "- ameluz-epar-product-information_en\n",
      "- ciambra-epar-product-information_en\n",
      "- capecitabine-accord-epar-product-information_en\n",
      "- caelyx-epar-product-information_en\n",
      "- bemfola-epar-product-information_en\n",
      "- atripla-epar-product-information_en\n",
      "- afinitor-epar-product-information_en\n",
      "- cholestagel-epar-product-information_en\n",
      "- coaprovel-epar-product-information_en\n",
      "- adempas-epar-product-information_en\n",
      "- bortezomib-accord-epar-product-information_en\n",
      "- arava-epar-product-information_en\n",
      "- avastin-epar-product-information_en\n",
      "- aldurazyme-epar-product-information_en\n",
      "- aloxi-epar-scientific-discussion_en\n",
      "- blitzima-epar-product-information_en\n",
      "- besponsa-epar-product-information_en\n",
      "- adcirca-epar-product-information_en\n"
     ]
    }
   ],
   "source": [
    "anames = list(annotations.keys())\n",
    "fnames = list(data.keys())\n",
    "\n",
    "# from scipy.spatial.distance import hamming\n",
    "\n",
    "# There's extra files referenced in the annotation spreadsheet\n",
    "print('anotation names count:', len(anames))\n",
    "print('document count:', len(fnames))\n",
    "\n",
    "missing_ann = set(fnames) - set(anames)\n",
    "missing_docs = set(anames) - set(fnames)\n",
    "\n",
    "print('missing annotations count:', len(missing_ann))\n",
    "print('missing doc count:', len(missing_docs))\n",
    "print('missing docs:')\n",
    "for doc_name in missing_docs:\n",
    "    print('-', doc_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for dataset\n",
    "    Every dataset is lower cased except\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"\\n\", \"\", string)    \n",
    "    string = re.sub(r\"\\r\", \"\", string) \n",
    "    string = re.sub(r\"[0-9]\", \"digit\", string)\n",
    "    string = re.sub(r\"\\'\", \"\", string)    \n",
    "    string = re.sub(r\"\\\"\", \"\", string)\n",
    "    return string.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean input text\n",
    "processed_documents = {}\n",
    "\n",
    "for doc_name in labeled_raw_documents:\n",
    "    texts = [clean_str(raw) for raw in labeled_raw_documents[doc_name]['paragraphs']]\n",
    "    labels = [l.lower() for l in labeled_raw_documents[doc_name]['labels']]\n",
    "    tags = [t.lower() for t in labeled_raw_documents[doc_name]['tags']]\n",
    "    \n",
    "    processed_documents[doc_name] = {\n",
    "        'texts': texts,\n",
    "        'labels': labels,\n",
    "        'tags': tags\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match text with the previous header\n",
    "for doc_name in processed_documents:\n",
    "    texts = processed_documents[doc_name]['texts']\n",
    "    tags = processed_documents[doc_name]['tags']\n",
    "    \n",
    "    # First Header\n",
    "    header_index = [-1] * len(texts)    \n",
    "    last_header = 0\n",
    "    \n",
    "    while(last_header < len(tags) and tags[last_header] != 'head'):\n",
    "        last_header += 1\n",
    "        \n",
    "    i = last_header + 1\n",
    "    \n",
    "    while i < len(tags):\n",
    "        header_index[i] = last_header\n",
    "        if tags[i] == 'head':\n",
    "            last_header = i\n",
    "        \n",
    "        i += 1\n",
    "    \n",
    "    # Second Header\n",
    "    header2 = [-1] * len(header_index)\n",
    "    last_header = 0\n",
    "    while(last_header < len(tags) and header_index[last_header] == -1):\n",
    "        last_header += 1\n",
    "    \n",
    "    i = last_header + 1\n",
    "    while i < len(header2):\n",
    "        header2[i] = header_index[last_header]\n",
    "        if header_index[i] != -1:\n",
    "            last_header = i\n",
    "        i += 1\n",
    "        \n",
    "    \n",
    "    \n",
    "    processed_documents[doc_name]['header_index'] = header_index\n",
    "    processed_documents[doc_name]['header_index_2'] = header2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create testing and training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from functools import reduce\n",
    "names = list(processed_documents.keys())\n",
    "\n",
    "rs = ShuffleSplit(n_splits=1, test_size = 0.3)\n",
    "split = next(rs.split(names))\n",
    "\n",
    "train_docs = list(map(lambda i: names[i], split[0]))\n",
    "test_docs = list(map(lambda i: names[i], split[1]))\n",
    "\n",
    "\n",
    "X_train = reduce(lambda l, dname: l + processed_documents[dname]['texts'], [[]] + train_docs)\n",
    "Y_train = reduce(lambda l, name: l + processed_documents[name]['labels'], [[]] + train_docs)\n",
    "\n",
    "\n",
    "X_test = reduce(lambda l, dname: l + processed_documents[dname]['texts'], [[]] + test_docs)\n",
    "Y_test = reduce(lambda l, name: l + processed_documents[name]['labels'], [[]] + test_docs)\n",
    "\n",
    "X = X_train + X_test\n",
    "Y = Y_train + Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text + Header\n",
    "from sklearn.feature_extraction.text import *\n",
    "\n",
    "# Count Tokenizer\n",
    "all_texts = set()\n",
    "all_headers = set()\n",
    "for doc_name in processed_documents:\n",
    "    texts = processed_documents[doc_name]['texts']\n",
    "    labels = processed_documents[doc_name]['labels']\n",
    "    header_index = processed_documents[doc_name]['header_index']\n",
    "    \n",
    "    all_texts = all_texts | set(texts)\n",
    "    all_headers = all_headers | set([texts[i] for i in header_index if i != -1])\n",
    "\n",
    "all_texts = sorted(list(all_texts))\n",
    "all_headers = sorted(list(all_headers))\n",
    "\n",
    "text_index = {el:i for i, el in enumerate(all_texts)}\n",
    "header_index = {el:i for i, el in enumerate(all_headers)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizer = CountVectorizer(ngram_range=(1, 4))\n",
    "all_texts = text_vectorizer.fit_transform(all_texts)\n",
    "\n",
    "header_vectorizer = CountVectorizer(ngram_range=(1, 4))\n",
    "all_headers = header_vectorizer.fit_transform(all_headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove data classes with insufficient examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_count = {el: Y.count(el) for el in set(Y)}\n",
    "\n",
    "min_count = 10\n",
    "X_train, Y_train = zip(*[(X_train[i], Y_train[i]) for i in range(len(X_train)) if Y_count[Y_train[i]] >= min_count])\n",
    "X_test, Y_test = zip(*[(X_test[i], Y_test[i]) for i in range(len(X_test)) if Y_count[Y_test[i]] >= min_count])\n",
    "\n",
    "X = X_train + X_test\n",
    "Y = Y_train + Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- significant findings | frequency: 21\n",
      "- significant findings | frequency: 41\n",
      "- populations - geriat | frequency: 41\n",
      "- populations - paedia | frequency: 76\n",
      "- populations - adult | frequency: 92\n",
      "- populations - adoles | frequency: 123\n",
      "- contraindication | frequency: 264\n",
      "- significant findings | frequency: 338\n",
      "- warning | frequency: 931\n",
      "- other | frequency: 25229\n"
     ]
    }
   ],
   "source": [
    "labels = list(set(Y))\n",
    "labels.sort(key=lambda x: Y.count(x))\n",
    "\n",
    "for l in labels:\n",
    "    print('-', l[:20], '| frequency:', Y.count(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Class SVN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline of feature engineering and model\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "model = Pipeline([('vectorizer', CountVectorizer()),\n",
    " ('tfidf', TfidfTransformer()),\n",
    " ('clf', OneVsRestClassifier(LinearSVC(class_weight='balanced')))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Param Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/csail.mit.edu/u/j/juanmoo1/bin/miniconda3/envs/myenv/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9035944242524167\n",
      "{'tfidf__use_idf': True, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 4), 'vectorizer__stop_words': None}\n"
     ]
    }
   ],
   "source": [
    "#paramater selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 4)],\n",
    "               'tfidf__use_idf': [False, True],\n",
    "               'vectorizer__min_df': [0, 0.0001, 0.00001],\n",
    "               'vectorizer__stop_words':[None, 'english']\n",
    "             }\n",
    "gs_clf_svm = GridSearchCV(model, parameters, n_jobs=-1)\n",
    "gs_clf_svm = gs_clf_svm.fit(X, Y)\n",
    "print(gs_clf_svm.best_score_)\n",
    "print(gs_clf_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# vectorizer = CountVectorizer(ngram_range=(1, 1), min_df=0.0001)\n",
    "# X2 = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7185"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/csail.mit.edu/u/j/juanmoo1/bin/miniconda3/envs/myenv/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "#Training of Final Model\n",
    "model = Pipeline([('vectorizer', CountVectorizer(ngram_range=(1,4), min_df = 0, stop_words=None)),\n",
    "    ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "    ('clf', OneVsRestClassifier(LinearSVC(class_weight=\"balanced\")))])\n",
    "\n",
    "model.fit(X_train, Y_train)\n",
    "#Test\n",
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  67   15    0    0    0    0    0    3    0    1]\n",
      " [  22 7619   84   28   46   41   18   80    0  147]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    2    0    0    1    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    2    1    0    0    1    0    0    0    0]\n",
      " [   0    2    0    0    0    0    0    0    0    0]\n",
      " [   0   36    0    0    0    0    0   76    0    0]\n",
      " [   0    7    0    0    0    0    0    0    0    0]\n",
      " [  18  140    0    0    1    0    2    0    0   86]]\n",
      "Class Acuracy: [0.7790697674418605, 0.9423623995052567, 0, 0.0, 0, 0.25, 0.0, 0.6785714285714286, 0.0, 0.3481781376518219]\n",
      "Overall Accuracy: 0.9184413760823777\n",
      "Accuracy excluding other: 0.49891540130151846\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(Y_test, pred)\n",
    "accuracy = accuracy_score(Y_test, pred)\n",
    "\n",
    "class_count = len(cm)\n",
    "\n",
    "class_accuracy = [cm[i][i]/sum(cm[i]) if sum(cm[i]) > 0 else 0 for i in range(class_count)]\n",
    "w_acc = [class_accuracy[i] * sum(cm[i]) for i in range(len(cm))]\n",
    "acc_no_other = (sum(w_acc) - w_acc[1])/(sum(sum(cm[i]) for i in range(class_count)) - sum(cm[1]))\n",
    "                                        \n",
    "print(cm)\n",
    "print('Class Acuracy:', class_accuracy)\n",
    "print('Overall Accuracy:', accuracy)\n",
    "print('Accuracy excluding other:', acc_no_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "other: acc 0.9423623995052567 total: 8085\n",
      "populations - adult: acc 0.0 total: 3\n",
      "contraindication: acc 0.7790697674418605 total: 86\n",
      "warning: acc 0.3481781376518219 total: 247\n",
      "significant findings - pregnancy: acc 0.6785714285714286 total: 112\n",
      "significant findings - renal impairment: acc 0.0 total: 7\n",
      "significant findings - hepatic impairment: acc 0.0 total: 2\n",
      "populations - paediatric: acc 0.25 total: 4\n"
     ]
    }
   ],
   "source": [
    "categories = dict()\n",
    "for real, prediction in zip(Y_test, pred):\n",
    "    if real not in categories:\n",
    "        categories[real] = [0,0] #total, correct\n",
    "    categories[real][0] += 1\n",
    "    categories[real][1] += (real == prediction)\n",
    "    \n",
    "for c in categories:\n",
    "    tot = categories[c][0]\n",
    "    corr = categories[c][1]\n",
    "    acc = corr/tot\n",
    "#     print(c + ' =>', 'total:', tot, '\\t\\t correct:', corr, '\\t\\t accuracy:', acc)\n",
    "    print(c + ': acc', acc, 'total:', tot)\n",
    "#     print(c + ': correct:', corr, \"\\t || accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO's 04/01/2020\n",
    "* Remove common words from text\n",
    "* Remove classes with few examples\n",
    "* Append Corresponding headers to examples\n",
    "* Limit length of feature vector // Filter low freq words\n",
    "* Stop words\n",
    "* Append BOG of corresponding header\n",
    "* Explore other models ?\n",
    "    ** Try decision tree\n",
    "    ** try small ff nn\n",
    "    \n",
    "* Separate train / test based on documents\n",
    "* Consider paragraphs w/o labels and 'other' label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Header in the feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['texts', 'labels', 'tags', 'header_index', 'header_index_2'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_doc_name = list(processed_documents.keys())[0]\n",
    "sample_doc = processed_documents[sample_doc_name]\n",
    "\n",
    "sample_doc.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import hstack, vstack\n",
    "\n",
    "# Create Feature vectors that tokenized version of last two headers\n",
    "for doc_name in processed_documents:\n",
    "    doc = processed_documents[doc_name]\n",
    "    \n",
    "    text_tokens = text_vectorizer.transform(doc['texts'])\n",
    "    header_tokens = header_vectorizer.transform([doc['texts'][i] if i != -1 else \"\" for i in doc['header_index']])\n",
    "    header2_tokens = header_vectorizer.transform([doc['texts'][i] if i != -1 else \"\" for i in doc['header_index_2']])\n",
    "    joint_tokens = hstack([text_tokens, header_tokens, header2_tokens])\n",
    "    \n",
    "    doc['tokens'] = joint_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from functools import reduce\n",
    "names = list(processed_documents.keys())\n",
    "\n",
    "rs = ShuffleSplit(n_splits=1, test_size = 0.3)\n",
    "split = next(rs.split(names))\n",
    "\n",
    "train_docs = list(map(lambda i: names[i], split[0]))\n",
    "test_docs = list(map(lambda i: names[i], split[1]))\n",
    "\n",
    "X_train = vstack([processed_documents[dname]['tokens'] for dname in train_docs])\n",
    "Y_train = reduce(lambda l, name: l + processed_documents[name]['labels'], [[]] + train_docs)\n",
    "\n",
    "X_test = vstack([processed_documents[dname]['tokens'] for dname in test_docs])\n",
    "Y_test = reduce(lambda l, name: l + processed_documents[name]['labels'], [[]] + test_docs)\n",
    "\n",
    "X = vstack([X_train , X_test])\n",
    "Y = Y_train + Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline of feature engineering and model\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "model = Pipeline([('tfidf', TfidfTransformer()),\n",
    " ('clf', OneVsRestClassifier(LinearSVC(class_weight='balanced')))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/csail.mit.edu/u/j/juanmoo1/bin/miniconda3/envs/myenv/lib/python3.8/site-packages/sklearn/model_selection/_split.py:665: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/afs/csail.mit.edu/u/j/juanmoo1/bin/miniconda3/envs/myenv/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9366370679155664\n",
      "{'tfidf__use_idf': True}\n"
     ]
    }
   ],
   "source": [
    "#paramater selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\n",
    "               'tfidf__use_idf': [False, True],\n",
    "             }\n",
    "\n",
    "gs_clf_svm = GridSearchCV(model, parameters, n_jobs=-1)\n",
    "gs_clf_svm = gs_clf_svm.fit(X, Y)\n",
    "print(gs_clf_svm.best_score_)\n",
    "print(gs_clf_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/csail.mit.edu/u/j/juanmoo1/bin/miniconda3/envs/myenv/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "#Training of Final Model\n",
    "model = Pipeline([\n",
    "    ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "    ('clf', OneVsRestClassifier(LinearSVC(class_weight=\"balanced\")))])\n",
    "\n",
    "model.fit(X_train, Y_train)\n",
    "#Test\n",
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  40   18    0    0    0    0    0    1    1    0    3]\n",
      " [  27 8292   13   20    2   37    0   12   61    0   99]\n",
      " [   0   11    0    0    0    0    0    0    0    0    0]\n",
      " [   0    1    0    0    0    0    0    0    0    0    0]\n",
      " [   1   10    0    0    0    0    0    0    1    0    1]\n",
      " [   0   25    0    0    0    8    0    0    0    0    2]\n",
      " [   0    1    0    0    0    0    0    0    0    0    0]\n",
      " [   2    8    0    0    0    0    0    0    0    0    0]\n",
      " [   1   46    0    0    0    0    0    0   42    0    1]\n",
      " [   0    1    0    0    0    0    0    0    0    0    0]\n",
      " [   5  108    0    0    0    7    0    1    2    0   39]]\n",
      "Class Acuracy: [0.6349206349206349, 0.9683522130094593, 0.0, 0.0, 0.0, 0.22857142857142856, 0.0, 0.0, 0.4666666666666667, 0.0, 0.24074074074074073]\n",
      "Overall Accuracy: 0.9408938547486033\n",
      "Accuracy excluding other: 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(Y_test, pred)\n",
    "accuracy = accuracy_score(Y_test, pred)\n",
    "\n",
    "class_count = len(cm)\n",
    "\n",
    "class_accuracy = [cm[i][i]/sum(cm[i]) if sum(cm[i]) > 0 else 0 for i in range(class_count)]\n",
    "w_acc = [class_accuracy[i] * sum(cm[i]) for i in range(len(cm))]\n",
    "acc_no_other = (sum(w_acc) - w_acc[1])/(sum(sum(cm[i]) for i in range(class_count)) - sum(cm[1]))\n",
    "                                        \n",
    "print(cm)\n",
    "print('Class Acuracy:', class_accuracy)\n",
    "print('Overall Accuracy:', accuracy)\n",
    "print('Accuracy excluding other:', acc_no_other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box Search with Header augmented feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.sparse import hstack, vstack\n",
    "from functools import reduce\n",
    "\n",
    "# Search Params\n",
    "ngram_configs = [(1, 1), (2, 2), (1, 2), (1, 3), (1, 4)]\n",
    "tfidf_configs = [True, False]\n",
    "vectorizer_stopwords_configs = ['english', None]\n",
    "\n",
    "# Vocab & Data Lists\n",
    "texts = set()\n",
    "headers = set()\n",
    "\n",
    "text_list = []\n",
    "label_list = []\n",
    "header1_list = []\n",
    "header2_list = []\n",
    "\n",
    "for doc_name in processed_documents:\n",
    "    doc = processed_documents[doc_name]\n",
    "    texts = texts | set(doc['texts'])\n",
    "    headers = headers | set(doc['texts'][i] for i in doc['header_index'] if i != -1)\n",
    "    \n",
    "    header1 = [doc['texts'][i] if i != -1 else \"\" for i in doc['header_index']]\n",
    "    header2 = [doc['texts'][i] if i != -1 else \"\" for i in doc['header_index_2']]\n",
    "    \n",
    "    doc['header1'] = header1\n",
    "    doc['header2'] = header2\n",
    "    \n",
    "    text_list.extend(doc['texts'])\n",
    "    label_list.extend(doc['labels'])\n",
    "    header1_list.extend(header1)\n",
    "    header2_list.extend(header2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/csail.mit.edu/u/j/juanmoo1/bin/miniconda3/envs/myenv/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/afs/csail.mit.edu/u/j/juanmoo1/bin/miniconda3/envs/myenv/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/afs/csail.mit.edu/u/j/juanmoo1/bin/miniconda3/envs/myenv/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/afs/csail.mit.edu/u/j/juanmoo1/bin/miniconda3/envs/myenv/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/afs/csail.mit.edu/u/j/juanmoo1/bin/miniconda3/envs/myenv/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/afs/csail.mit.edu/u/j/juanmoo1/bin/miniconda3/envs/myenv/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/afs/csail.mit.edu/u/j/juanmoo1/bin/miniconda3/envs/myenv/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/afs/csail.mit.edu/u/j/juanmoo1/bin/miniconda3/envs/myenv/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/afs/csail.mit.edu/u/j/juanmoo1/bin/miniconda3/envs/myenv/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/afs/csail.mit.edu/u/j/juanmoo1/bin/miniconda3/envs/myenv/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/afs/csail.mit.edu/u/j/juanmoo1/bin/miniconda3/envs/myenv/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/afs/csail.mit.edu/u/j/juanmoo1/bin/miniconda3/envs/myenv/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/afs/csail.mit.edu/u/j/juanmoo1/bin/miniconda3/envs/myenv/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/afs/csail.mit.edu/u/j/juanmoo1/bin/miniconda3/envs/myenv/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/afs/csail.mit.edu/u/j/juanmoo1/bin/miniconda3/envs/myenv/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/afs/csail.mit.edu/u/j/juanmoo1/bin/miniconda3/envs/myenv/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/afs/csail.mit.edu/u/j/juanmoo1/bin/miniconda3/envs/myenv/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/afs/csail.mit.edu/u/j/juanmoo1/bin/miniconda3/envs/myenv/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/afs/csail.mit.edu/u/j/juanmoo1/bin/miniconda3/envs/myenv/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/afs/csail.mit.edu/u/j/juanmoo1/bin/miniconda3/envs/myenv/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9750009204373918, {'stop_config': 'english', 'ngram_config': (1, 4), 'tfidf_config': True})\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "best_config = (-1, None)\n",
    "for stop_config in vectorizer_stopwords_configs:\n",
    "    for ngram_config in ngram_configs:\n",
    "        # Build Dataset w/ given ngram\n",
    "\n",
    "        text_tokenizer = CountVectorizer(ngram_range=ngram_config, stop_words=stop_config)\n",
    "        header_tokenizer = CountVectorizer(ngram_range=ngram_config, stop_words=stop_config)\n",
    "\n",
    "        text_tokenizer.fit(texts)\n",
    "        header_tokenizer.fit(headers)\n",
    "\n",
    "        tokenized_texts = text_tokenizer.transform(text_list)\n",
    "        tokenized_header1 = header_tokenizer.transform(header1_list)\n",
    "        tokenized_header2 = header_tokenizer.transform(header2_list)\n",
    "\n",
    "        X = hstack([tokenized_texts, tokenized_header1, tokenized_header2])\n",
    "        Y = label_list\n",
    "\n",
    "        for tfidf_config in tfidf_configs:\n",
    "                model = Pipeline([('tfidf', TfidfTransformer(use_idf=tfidf_config)),\n",
    "                                  ('clf', OneVsRestClassifier(LinearSVC(class_weight=\"balanced\")))])\n",
    "                model.fit(X, Y)\n",
    "                \n",
    "                pred = model.predict(X)\n",
    "                accuracy = accuracy_score(Y, pred)\n",
    "                if accuracy > best_config[0]:\n",
    "                    config = {\n",
    "                                'stop_config': stop_config,\n",
    "                                'ngram_config': ngram_config,\n",
    "                                'tfidf_config': tfidf_config\n",
    "                             }\n",
    "                    best_config = (accuracy, config)\n",
    "print(best_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/csail.mit.edu/u/j/juanmoo1/bin/miniconda3/envs/myenv/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from functools import reduce\n",
    "\n",
    "# Test/Train Split\n",
    "names = list(processed_documents.keys())\n",
    "rs = ShuffleSplit(n_splits=1, test_size = 0.3)\n",
    "split = next(rs.split(names))\n",
    "train_docs = list(map(lambda i: names[i], split[0]))\n",
    "test_docs = list(map(lambda i: names[i], split[1]))\n",
    "\n",
    "# Train\n",
    "train_texts = reduce(lambda x, y: x + y, [[]] + [processed_documents[doc_name]['texts'] for doc_name in train_docs])\n",
    "train_header1 = reduce(lambda x, y: x + y, [[]] + [processed_documents[doc_name]['header1'] for doc_name in train_docs])\n",
    "train_header2 = reduce(lambda x, y: x + y, [[]] + [processed_documents[doc_name]['header2'] for doc_name in train_docs])\n",
    "train_labels = reduce(lambda x, y: x + y, [[]] + [processed_documents[doc_name]['labels'] for doc_name in train_docs])\n",
    "\n",
    "# Test\n",
    "test_texts = reduce(lambda x, y: x + y, [[]] + [processed_documents[doc_name]['texts'] for doc_name in test_docs])\n",
    "test_header1 = reduce(lambda x, y: x + y, [[]] + [processed_documents[doc_name]['header1'] for doc_name in test_docs])\n",
    "test_header2 = reduce(lambda x, y: x + y, [[]] + [processed_documents[doc_name]['header2'] for doc_name in test_docs])\n",
    "test_labels = reduce(lambda x, y: x + y, [[]] + [processed_documents[doc_name]['labels'] for doc_name in test_docs])\n",
    "\n",
    "\n",
    "# Final Model\n",
    "_, config = best_config\n",
    "text_tokenizer = CountVectorizer(ngram_range=config['ngram_config'], stop_words=config['stop_config'])\n",
    "header_tokenizer = CountVectorizer(ngram_range=config['ngram_config'], stop_words=config['stop_config'])\n",
    "\n",
    "tokenized_texts = text_tokenizer.fit_transform(train_texts)\n",
    "tokenized_header1 = header_tokenizer.fit_transform(train_header1)\n",
    "tokenized_header2 = header_tokenizer.transform(train_header2)\n",
    "X_train = hstack([tokenized_texts, tokenized_header1, tokenized_header2])\n",
    "Y_train = train_labels\n",
    "\n",
    "model = Pipeline([('tfidf', TfidfTransformer(use_idf=config['tfidf_config'])), ('clf', OneVsRestClassifier(LinearSVC(class_weight=\"balanced\")))])\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# Test Final Model\n",
    "tokenized_texts = text_tokenizer.transform(test_texts)\n",
    "tokenized_header1 = header_tokenizer.transform(test_header1)\n",
    "tokenized_header2 = header_tokenizer.transform(test_header2)\n",
    "X_test = hstack([tokenized_texts, tokenized_header1, tokenized_header2])\n",
    "Y_test = test_labels\n",
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[  75   10    0    0    2    0    0    2    0    2]\n",
      " [  12 5799   40   17   18   29   33   79    4  133]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    1    0    0    0    0    0    0    0    0]\n",
      " [   0    2    0    0    0    0    0    0    0    0]\n",
      " [   0   21    1    0    0    7    0    0    0    0]\n",
      " [   0    1    0    0    0    0    0    0    0    0]\n",
      " [   1   25    0    0    0    1    0  102    0    0]\n",
      " [   0    3    0    0    0    0    0    0    0    0]\n",
      " [  14  170    0    0    0    0    1   10    0  172]]\n",
      "Class Acuracy: [0.8241758241758241, 0.9407852044127191, 0, 0.0, 0.0, 0.2413793103448276, 0.0, 0.7906976744186046, 0.0, 0.46866485013623976]\n",
      "Overall Accuracy: 0.9068808015323412\n",
      "Accuracy excluding other: 0.5714285714285714\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(Y_test, pred)\n",
    "accuracy = accuracy_score(Y_test, pred)\n",
    "\n",
    "class_count = len(cm)\n",
    "\n",
    "class_accuracy = [cm[i][i]/sum(cm[i]) if sum(cm[i]) > 0 else 0 for i in range(class_count)]\n",
    "w_acc = [class_accuracy[i] * sum(cm[i]) for i in range(len(cm))]\n",
    "acc_no_other = (sum(w_acc) - w_acc[1])/(sum(sum(cm[i]) for i in range(class_count)) - sum(cm[1]))\n",
    "                                        \n",
    "print('Confusion Matrix:\\n', cm)\n",
    "print('Class Acuracy:', class_accuracy)\n",
    "print('Overall Accuracy:', accuracy)\n",
    "print('Accuracy excluding other:', acc_no_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
