{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.abspath('./src'))\n",
    "import utils, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATHS\n",
    "data_path = '/data/rsg/nlp/fake_proj/__temp__juanmoo__'\n",
    "EMA_dump_path = os.path.join(data_path, './jsons/EMA_dump.json')\n",
    "EMA_xmls_path = os.path.join(data_path, './xmls/')\n",
    "EMA_annotations_path = os.path.join(data_path, './bayer/VendorEMAforMIT/annotations.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw Data\n",
    "data = json.loads(open(EMA_dump_path, 'r').read())\n",
    "'''\n",
    "Format:\n",
    "[\n",
    "    document_name: <str>: {\n",
    "                            document_name: <str>,\n",
    "                            element_text: <str> (raw text),\n",
    "                            processed_text: <str> (lowercase, only alphanumeric),\n",
    "                            element_tag: <str> (TEI XML tag)\n",
    "                          },\n",
    "                          \n",
    "    ...\n",
    "]\n",
    "'''\n",
    "\n",
    "# Labels\n",
    "'''\n",
    "Dict in form:\n",
    "{\n",
    "    file_name: {\n",
    "        texts: [ <str>, ...],\n",
    "        labels: [ <str>, ...]\n",
    "    },\n",
    "    \n",
    "    ...\n",
    "    \n",
    "}\n",
    "'''\n",
    "annotations = utils.parse_spreadsheet(EMA_annotations_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching Data to Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_paragraph_length = 2\n",
    "\n",
    "paragraphs = []\n",
    "labels = []\n",
    "\n",
    "for doc_name in data:\n",
    "    assert(doc_name in annotations)\n",
    "    \n",
    "    for t in data[doc_name]['element_text']:\n",
    "        if len(t) >=  min_paragraph_length:\n",
    "            for i, text_candidate in enumerate(annotations[doc_name]['texts']):\n",
    "                if t in text_candidate:\n",
    "                    paragraphs.append(t)\n",
    "                    labels.append(annotations[doc_name]['labels'][i])\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parlen: 1258\n",
      "lablen: 1258\n"
     ]
    }
   ],
   "source": [
    "print('parlen:', len(paragraphs))\n",
    "print('lablen:', len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for dataset\n",
    "    Every dataset is lower cased except\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"\\n\", \"\", string)    \n",
    "    string = re.sub(r\"\\r\", \"\", string) \n",
    "    string = re.sub(r\"[0-9]\", \"digit\", string)\n",
    "    string = re.sub(r\"\\'\", \"\", string)    \n",
    "    string = re.sub(r\"\\\"\", \"\", string)\n",
    "    return string.strip().lower()\n",
    "\n",
    "X = [clean_str(raw) for raw in paragraphs]\n",
    "Y = [l.lower() for l in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline of feature engineering and model\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "model = Pipeline([('vectorizer', CountVectorizer()),\n",
    " ('tfidf', TfidfTransformer()),\n",
    " ('clf', OneVsRestClassifier(LinearSVC(class_weight='balanced')))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/csail.mit.edu/u/j/juanmoo1/bin/miniconda3/envs/myenv/lib/python3.8/site-packages/sklearn/model_selection/_split.py:665: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8362486561689749\n",
      "{'tfidf__use_idf': True, 'vectorizer__ngram_range': (1, 1)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/csail.mit.edu/u/j/juanmoo1/bin/miniconda3/envs/myenv/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "#paramater selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'vectorizer__ngram_range': [(i, j) for i in range(1, 5) for j in range(1, 5)],\n",
    "               'tfidf__use_idf': (True, False)}\n",
    "gs_clf_svm = GridSearchCV(model, parameters, n_jobs=-1)\n",
    "gs_clf_svm = gs_clf_svm.fit(X, Y)\n",
    "print(gs_clf_svm.best_score_)\n",
    "print(gs_clf_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/csail.mit.edu/u/j/juanmoo1/bin/miniconda3/envs/myenv/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 31,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,  26,   0,   0,   3,   0,   0,   0,   0,   2],\n",
       "       [  0,   1,  32,   1,   0,   0,   0,   0,   0,   1],\n",
       "       [  0,   0,   0,   4,   0,   0,   0,   2,   0,   2],\n",
       "       [  0,   7,   0,   1,  20,   0,   0,   0,   0,   5],\n",
       "       [  0,   0,   0,   0,   0,   8,   0,   1,   0,   3],\n",
       "       [  0,   0,   0,   0,   0,   0,   1,   0,   0,   0],\n",
       "       [  3,   0,   0,   0,   0,   0,   0,  50,   0,   1],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   1,   0,   0],\n",
       "       [  7,   0,   0,   1,   0,   1,   0,   5,   1, 157]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Pipeline([('vectorizer', CountVectorizer(ngram_range=(1,1))),\n",
    "    ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "    ('clf', OneVsRestClassifier(LinearSVC(class_weight=\"balanced\")))])\n",
    "\n",
    "#Training of Final Model\n",
    "model.fit(X_train, y_train)\n",
    "#Test\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "confusion_matrix(pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO's\n",
    "* Remove common words from text\n",
    "* Remove classes with few examples\n",
    "* Append Corresponding headers to examples\n",
    "* Explore other models ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
